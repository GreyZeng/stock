{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ca60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始获取可转债数据，请稍候...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac1ad4aad704aa996c4a7afdd4a8eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\akshare\\bond\\bond_zh_cov.py:342: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  big_df = pd.concat(objs=[big_df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功获取并保存到文件: 可转债数据清单.xlsx\n",
      "共获取到 983 条数据。\n"
     ]
    }
   ],
   "source": [
    "# 1. 导入需要的库\n",
    "import akshare as ak  # akshare 是核心的数据获取库\n",
    "import pandas as pd    # pandas 用于数据处理和保存到Excel\n",
    "\n",
    "print(\"开始获取可转债数据，请稍候...\")\n",
    "\n",
    "try:\n",
    "    # 2. 调用接口获取可转债数据\n",
    "    # ak.bond_zh_cov() 会返回一个pandas的DataFrame对象，这是一种表格形式的数据结构。\n",
    "    bond_zh_cov_df = ak.bond_zh_cov()\n",
    "\n",
    "    # 3. 定义你想要保存的文件名\n",
    "    file_name = \"可转债数据清单.xlsx\"\n",
    "\n",
    "    # 4. 将数据保存到Excel文件\n",
    "    # 我们使用 to_excel 方法。其中：\n",
    "    # - excel_writer: 指定了要保存的文件路径和名称。\n",
    "    # - index=False: 这是一个很重要的参数。如果不设置，pandas会默认把数据行的索引（0, 1, 2, ...）也写进Excel的第一列，通常我们不希望这样，所以设为False。\n",
    "    # - engine='openpyxl': 明确指定使用 openpyxl 引擎来写入xlsx文件。\n",
    "    bond_zh_cov_df.to_excel(excel_writer=file_name, index=False, engine='openpyxl')\n",
    "\n",
    "    # 5. 打印成功信息\n",
    "    # 给出一个明确的提示，告知用户文件已经成功生成以及它的名字。\n",
    "    print(f\"数据已成功获取并保存到文件: {file_name}\")\n",
    "    print(f\"共获取到 {len(bond_zh_cov_df)} 条数据。\")\n",
    "\n",
    "except Exception as e:\n",
    "    # 6. 异常处理\n",
    "    # 如果在获取或保存数据的过程中发生任何错误，打印出错误信息，方便排查问题。\n",
    "    print(f\"处理过程中发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d952b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从同花顺获取可转债数据，这可能需要一点时间...\n",
      "数据成功保存至文件: 可转债数据清单_同花顺.xlsx\n",
      "本次共获取 890 条可转债数据。\n"
     ]
    }
   ],
   "source": [
    "# 1. 导入我们需要的库\n",
    "import akshare as ak  # akshare 是获取数据的核心\n",
    "import pandas as pd    # pandas 用于数据处理和与Excel交互\n",
    "\n",
    "print(\"正在从同花顺获取可转债数据，这可能需要一点时间...\")\n",
    "\n",
    "try:\n",
    "    # 2. 调用同花顺的接口获取可转债数据\n",
    "    # 这次我们使用的是 bond_zh_cov_info_ths 函数\n",
    "    bond_data_df = ak.bond_zh_cov_info_ths()\n",
    "\n",
    "    # 3. 为文件命名，最好能区分出来源\n",
    "    file_name = \"可转债数据清单_同花顺.xlsx\"\n",
    "\n",
    "    # 4. 将数据写入Excel文件\n",
    "    # 同样，我们使用 to_excel 方法，并且不保存pandas的索引列\n",
    "    bond_data_df.to_excel(excel_writer=file_name, index=False, engine='openpyxl')\n",
    "\n",
    "    # 5. 任务完成，给出一个清晰的反馈\n",
    "    print(f\"数据成功保存至文件: {file_name}\")\n",
    "    print(f\"本次共获取 {len(bond_data_df)} 条可转债数据。\")\n",
    "\n",
    "except Exception as e:\n",
    "    # 6. 如果过程中出现任何问题，友好地提示错误\n",
    "    print(f\"在处理过程中发生了错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732399ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "任务开始：准备合并与对比东方财富和同花顺的可转债数据...\n",
      "步骤 1/5: 正在获取东方财富数据...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba115e052a6c4842b7d70e6390b1541c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\akshare\\bond\\bond_zh_cov.py:342: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  big_df = pd.concat(objs=[big_df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤 2/5: 正在获取同花顺数据...\n",
      "步骤 3/5: 已为数据列名添加来源前缀。\n",
      "步骤 4/5: 数据合并完成。\n",
      "步骤 5/5: 处理完成！\n",
      "合并后的数据已保存至文件: 可转债数据对比表.xlsx\n",
      "文件中包含了并列对比的列和来源标识，方便您进行下一步分析。\n"
     ]
    }
   ],
   "source": [
    "# 1. 导入必要的库\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "print(\"任务开始：准备合并与对比东方财富和同花顺的可转债数据...\")\n",
    "\n",
    "try:\n",
    "    # 2. 分别获取两份数据\n",
    "    print(\"步骤 1/5: 正在获取东方财富数据...\")\n",
    "    em_df = ak.bond_zh_cov()\n",
    "    print(\"步骤 2/5: 正在获取同花顺数据...\")\n",
    "    ths_df = ak.bond_zh_cov_info_ths()\n",
    "\n",
    "    # 3. 为两份数据的列名添加来源前缀\n",
    "    # 这是关键一步，确保合并后能清晰地区分每个字段的来源\n",
    "    em_df_prefixed = em_df.add_prefix('东方财富_')\n",
    "    ths_df_prefixed = ths_df.add_prefix('同花顺_')\n",
    "    print(\"步骤 3/5: 已为数据列名添加来源前缀。\")\n",
    "\n",
    "    # 4. 执行数据合并\n",
    "    # 我们使用 'outer' 合并策略，确保任何一方独有的数据都不会丢失。\n",
    "    # 合并的关键键是各自的'债券代码'。\n",
    "    # indicator=True 会自动生成一个名为 '_merge' 的列，告诉我们每一行的来源状态。\n",
    "    merged_df = pd.merge(\n",
    "        em_df_prefixed,\n",
    "        ths_df_prefixed,\n",
    "        left_on='东方财富_债券代码',\n",
    "        right_on='同花顺_债券代码',\n",
    "        how='outer',\n",
    "        indicator=True\n",
    "    )\n",
    "    print(\"步骤 4/5: 数据合并完成。\")\n",
    "\n",
    "    # 5. 根据合并结果创建来源标识列\n",
    "    # 将 '_merge' 列的专业术语（left_only, right_only, both）转换成你想要的中文描述。\n",
    "    status_map = {\n",
    "        'left_only': '仅东方财富',\n",
    "        'right_only': '仅同花顺',\n",
    "        'both': '同时存在'\n",
    "    }\n",
    "    merged_df['数据来源'] = merged_df['_merge'].map(status_map)\n",
    "    merged_df = merged_df.drop(columns=['_merge']) # 用完后就删掉辅助列\n",
    "\n",
    "    # 6. 精心重排列表，实现“近似列并列”的效果\n",
    "    # 这部分是实现你核心需求的魔法。我们手动定义一个理想的列顺序。\n",
    "    # 首先，定义好我们希望并排对比的列\n",
    "    paired_columns = [\n",
    "        '东方财富_债券代码', '同花顺_债券代码',\n",
    "        '东方财富_债券简称', '同花顺_债券简称',\n",
    "        '东方财富_上市时间', '同花顺_上市日期',\n",
    "        '东方财富_申购日期', '同花顺_申购日期',\n",
    "        '东方财富_申购代码', '同花顺_申购代码',\n",
    "        '东方财富_正股代码', '同花顺_正股代码',\n",
    "        '东方财富_正股简称', '同花顺_正股简称',\n",
    "        '东方财富_转股价', '同花顺_转股价格',\n",
    "        '东方财富_中签率', '同花顺_中签率',\n",
    "        '东方财富_中签号发布日', '同花顺_中签公布日',\n",
    "        '东方财富_原股东配售-每股配售额', '同花顺_每股获配额',\n",
    "    ]\n",
    "\n",
    "    # 然后，找出那些只在某一个数据源存在的列\n",
    "    all_current_columns = merged_df.columns.tolist()\n",
    "    unique_columns = [col for col in all_current_columns if col not in paired_columns and col != '数据来源']\n",
    "    \n",
    "    # 最终的列顺序：并列对比的列 + 独有的列 + 我们创建的来源标识列\n",
    "    final_column_order = paired_columns + unique_columns + ['数据来源']\n",
    "    \n",
    "    # 应用这个顺序\n",
    "    final_df = merged_df[final_column_order]\n",
    "\n",
    "    # 7. 保存到Excel\n",
    "    file_name = \"可转债数据对比表.xlsx\"\n",
    "    final_df.to_excel(file_name, index=False, engine='openpyxl')\n",
    "    \n",
    "    print(f\"步骤 5/5: 处理完成！\")\n",
    "    print(f\"合并后的数据已保存至文件: {file_name}\")\n",
    "    print(\"文件中包含了并列对比的列和来源标识，方便您进行下一步分析。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"处理过程中发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d57587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "启动最终版数据清洗任务（已修正过滤规则）...\n",
      "正在获取东方财富和同花顺数据...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca19f4ea7cd046dcae548b049d8c1117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\akshare\\bond\\bond_zh_cov.py:342: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  big_df = pd.concat(objs=[big_df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据获取与初步合并完成。\n",
      "正在执行精准过滤，分离可转债与非可转债记录...\n",
      "过滤完成。总计 984 条，保留 964 条进行下一步处理，剔除 20 条非可转债记录。\n",
      "被剔除的记录已保存至: 非可转债记录清单.xlsx\n",
      "正在为可转债数据添加'债券状态'标记...\n",
      "正在执行各批次数据清洗...\n",
      "所有清洗批次执行完毕。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\1\\ipykernel_2940\\3774583776.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  main_df[left_col].fillna(main_df[right_col], inplace=True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\1\\ipykernel_2940\\3774583776.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  main_df[right_col].fillna(main_df[left_col], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "任务成功完成！\n",
      "专为回测优化的全量数据集已保存至: 可转债全量数据_清洗后(含退市).xlsx\n"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"启动最终版数据清洗任务（已修正过滤规则）...\")\n",
    "\n",
    "try:\n",
    "    # === 步骤 1: 获取并合并原始数据 ===\n",
    "    print(\"正在获取东方财富和同花顺数据...\")\n",
    "    em_df = ak.bond_zh_cov()\n",
    "    ths_df = ak.bond_zh_cov_info_ths()\n",
    "\n",
    "    em_df_prefixed = em_df.add_prefix('东方财富_')\n",
    "    ths_df_prefixed = ths_df.add_prefix('同花顺_')\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        em_df_prefixed,\n",
    "        ths_df_prefixed,\n",
    "        left_on='东方财富_债券代码',\n",
    "        right_on='同花顺_债券代码',\n",
    "        how='outer',\n",
    "        indicator=True\n",
    "    )\n",
    "    \n",
    "    status_map = {'left_only': '仅东方财富', 'right_only': '仅同花顺', 'both': '同时存在'}\n",
    "    merged_df['数据来源'] = merged_df['_merge'].map(status_map)\n",
    "    merged_df.drop(columns=['_merge'], inplace=True)\n",
    "    print(\"数据获取与初步合并完成。\")\n",
    "\n",
    "    # === 步骤 2: **修正并执行**精准过滤 ===\n",
    "    print(\"正在执行精准过滤，分离可转债与非可转债记录...\")\n",
    "    initial_rows = len(merged_df)\n",
    "\n",
    "    # **核心修正**: 使用 str.contains() 来实现更灵活的匹配\n",
    "    # 条件：简称中包含“债”，但**不包含**“转债”\n",
    "    is_non_convertible_bond = (merged_df['东方财富_债券简称'].str.contains('债', na=False)) & \\\n",
    "                              (~merged_df['东方财富_债券简称'].str.contains('转债', na=False))\n",
    "\n",
    "    # 根据这个更精准的规则来分离数据\n",
    "    filtered_out_df = merged_df[is_non_convertible_bond].copy()\n",
    "    main_df = merged_df[~is_non_convertible_bond].copy()\n",
    "    \n",
    "    # === 步骤 3: 保存被过滤掉的非可转债记录 ===\n",
    "    removed_file_name = \"非可转债记录清单.xlsx\"\n",
    "    filtered_out_df.to_excel(removed_file_name, index=False, engine='openpyxl')\n",
    "    \n",
    "    print(f\"过滤完成。总计 {initial_rows} 条，保留 {len(main_df)} 条进行下一步处理，剔除 {len(filtered_out_df)} 条非可转债记录。\")\n",
    "    print(f\"被剔除的记录已保存至: {removed_file_name}\")\n",
    "\n",
    "    # === 步骤 4: 在核心数据中“标记”退市状态 ===\n",
    "    print(\"正在为可转债数据添加'债券状态'标记...\")\n",
    "    main_df['债券状态'] = '正常'\n",
    "    main_df.loc[main_df['东方财富_债券简称'].str.contains('退', na=False), '债券状态'] = '已退市'\n",
    "\n",
    "    # === 步骤 5: 对保留的全部可转债数据进行深度清洗 ===\n",
    "    print(\"正在执行各批次数据清洗...\")\n",
    "    # --- 第一批：统一正股简称 ---\n",
    "    condition = (main_df['数据来源'] == '同时存在') & \\\n",
    "                (main_df['东方财富_正股简称'].notna()) & (main_df['同花顺_正股简称'].notna()) & \\\n",
    "                (main_df['东方财富_正股简称'] != main_df['同花顺_正股简称'])\n",
    "    main_df.loc[condition, '东方财富_正股简称'] = main_df.loc[condition, '同花顺_正股简称']\n",
    "    \n",
    "    # --- 第二批：标准化“中签率”单位 ---\n",
    "    main_df['东方财富_中签率'] = pd.to_numeric(main_df['东方财富_中签率'], errors='coerce')\n",
    "    main_df['同花顺_中签率'] = pd.to_numeric(main_df['同花顺_中签率'], errors='coerce')\n",
    "    cond_em_large = main_df['东方财富_中签率'] > (main_df['同花顺_中签率'] * 99)\n",
    "    main_df.loc[cond_em_large, '东方财富_中签率'] /= 100\n",
    "\n",
    "    # --- 第三批：清理并统一“中签号”格式 ---\n",
    "    main_df['同花顺_中签号'] = main_df['同花顺_中签号'].astype(str).str.replace(r'[；、\\s\\n]+', ',', regex=True).str.strip(',')\n",
    "\n",
    "    # --- 第四批：补充关键字段的缺失值 ---\n",
    "    paired_columns_map = {\n",
    "        '东方财富_上市时间': '同花顺_上市日期', '东方财富_申购日期': '同花顺_申购日期',\n",
    "        '东方财富_转股价': '同花顺_转股价格', '东方财富_中签率': '同花顺_中签率'\n",
    "    }\n",
    "    for left_col, right_col in paired_columns_map.items():\n",
    "        main_df[left_col].fillna(main_df[right_col], inplace=True)\n",
    "        main_df[right_col].fillna(main_df[left_col], inplace=True)\n",
    "    \n",
    "    print(\"所有清洗批次执行完毕。\")\n",
    "\n",
    "    # === 步骤 6: 重排列表并保存最终的回测专用数据集 ===\n",
    "    status_col = ['债券状态']\n",
    "    paired_columns_order = [\n",
    "        '东方财富_债券代码', '同花顺_债券代码', '东方财富_债券简称', '同花顺_债券简称',\n",
    "        '东方财富_上市时间', '同花顺_上市日期', '东方财富_申购日期', '同花顺_申购日期',\n",
    "        '东方财富_申购代码', '同花顺_申购代码', '东方财富_正股代码', '同花顺_正股代码',\n",
    "        '东方财富_正股简称', '同花顺_正股简称', '东方财富_转股价', '同花顺_转股价格',\n",
    "        '东方财富_中签率', '同花顺_中签率'\n",
    "    ]\n",
    "    all_current_columns = main_df.columns.tolist()\n",
    "    unique_columns = [col for col in all_current_columns if col not in (paired_columns_order + status_col + ['数据来源'])]\n",
    "    final_column_order = status_col + paired_columns_order + unique_columns + ['数据来源']\n",
    "    final_df = main_df[final_column_order]\n",
    "\n",
    "    cleaned_file_name = \"可转债全量数据_清洗后(含退市).xlsx\"\n",
    "    final_df.to_excel(cleaned_file_name, index=False, engine='openpyxl')\n",
    "    \n",
    "    print(\"\\n任务成功完成！\")\n",
    "    print(f\"专为回测优化的全量数据集已保存至: {cleaned_file_name}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n处理过程中发生错误: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
